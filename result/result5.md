
```Context Maximisation Error:  couldn't capture sentence index.```

```../data/C90-2039_TRAIN/citance_XML/C92-2068.xml```

```Context Maximisation Error:  couldn't capture sentence index.```

```../data/C90-2039_TRAIN/citance_XML/W97-1503.xml```

##Total Features Number using contrast: 187 / 125

### mainpulating the section : 0

1 - **represent**: ,Contrast

2 - **skeleton**: ,Contrast  ,Feature

3 - **environment**: ,Contrast

4 - **information**: ,Contrast  ,Feature

5 - **natural**: ,Contrast  ,Feature

6 - **developed**: ,Contrast

7 - **terms**: ,Contrast

8 - **methods**: ,Contrast  ,Feature  ,Abstract

9 - **language**: ,Contrast  ,Feature  ,Abstract

10 - **grammatical**: ,Contrast

11 - **systems**: ,Contrast  ,Feature  ,Abstract

12 - **part**: ,Contrast  ,Feature

13 - **representing**: ,Contrast

14 - **based**: ,Contrast  ,Feature

15 - **ire**: ,Contrast

16 - **strategy**: ,Contrast  ,Feature  ,Abstract

17 - **copying**: ,Contrast  ,Feature

18 - **proposed**: ,Contrast  ,Feature

19 - **inputs**: ,Contrast  ,Feature

20 - **unification**: ,Contrast  ,Feature  ,Abstract

21 - **disadvantages**: ,Contrast

22 - **unnecessary**: ,Contrast

23 - **processing**: ,Contrast  ,Feature

24 - **constraints**: ,Contrast  ,Feature

25 - **called**: ,Contrast  ,Feature

26 - **formalisms**: ,Contrast  ,Feature

27 - **structures**: ,Contrast  ,Feature  ,Abstract

28 - **time**: ,Contrast  ,Abstract

### mainpulating the section : 1

1 - **partial**: ,Contrast

2 - **represented**: ,Contrast  ,Feature

3 - **feature**: ,Contrast  ,Feature  ,Abstract

4 - **description**: ,Contrast

5 - **typed**: ,Contrast

6 - **rooted**: ,Contrast

7 - **ordering**: ,Contrast

8 - **relationships**: ,Contrast  ,Feature

9 - **pairs**: ,Contrast  ,Feature

10 - **feature-value**: ,Contrast  ,Feature

11 - **exists**: ,Contrast

12 - **ares**: ,Contrast  ,Feature

13 - **equal**: ,Contrast  ,Feature

14 - **merging**: ,Contrast

15 - **empty**: ,Contrast

16 - **properties**: ,Contrast

17 - **dereference**: ,Contrast

18 - **lower**: ,Contrast

19 - **greatest**: ,Contrast  ,Feature

20 - **describing**: ,Contrast

21 - **bound**: ,Contrast

22 - **directed**: ,Contrast  ,Feature

23 - **describe**: ,Contrast

24 - **symbol**: ,Contrast  ,Feature

### mainpulating the section : 2

1 - **computation**: ,Contrast  ,Abstract

2 - **current**: ,Contrast  ,Feature

3 - **shared**: ,Contrast  ,Feature

4 - **paths**: ,Contrast

5 - **obtained**: ,Contrast

6 - **meet**: ,Contrast  ,Feature

7 - **give**: ,Contrast

8 - **tile**: ,Contrast  ,Feature

9 - **modification**: ,Contrast

10 - **represents**: ,Contrast

11 - **contents**: ,Contrast  ,Feature

12 - **created**: ,Contrast  ,Feature

13 - **recursively**: ,Contrast

14 - **results**: ,Contrast  ,Feature

15 - **takes**: ,Contrast  ,Feature

16 - **common**: ,Contrast

17 - **arc**: ,Contrast  ,Feature

18 - **labels**: ,Contrast  ,Feature

19 - **subgraphs**: ,Contrast  ,Feature

20 - **treats**: ,Contrast  ,Feature

21 - **copied**: ,Contrast  ,Feature

22 - **values**: ,Contrast  ,Feature

23 - **procedure**: ,Contrast  ,Feature

24 - **dereference**: ,Contrast

25 - **proposes**: ,Contrast

26 - **inputs**: ,Contrast  ,Feature

27 - **node**: ,Contrast  ,Feature

28 - **required**: ,Contrast

29 - **original**: ,Contrast

### mainpulating the section : 3

1 - **existing**: ,Contrast

2 - **consisting**: ,Contrast  ,Feature

3 - **larger**: ,Contrast

4 - **erg**: ,Contrast  ,Feature

5 - **returns**: ,Contrast  ,Feature

6 - **found**: ,Contrast

7 - **newly**: ,Contrast  ,Feature

8 - **size**: ,Contrast

9 - **copies**: ,Contrast  ,Feature  ,Abstract

10 - **results**: ,Contrast  ,Feature

11 - **slots**: ,Contrast  ,Feature

12 - **disjunctive**: ,Contrast

13 - **depends**: ,Contrast

14 - **arc**: ,Contrast  ,Feature

15 - **ares**: ,Contrast  ,Feature

16 - **disjunct**: ,Contrast

17 - **definite**: ,Contrast  ,Feature

18 - **ire**: ,Contrast

19 - **copied**: ,Contrast  ,Feature

20 - **applies**: ,Contrast

21 - **procedure**: ,Contrast  ,Feature

22 - **temporary**: ,Contrast

23 - **sentence**: ,Contrast

24 - **adds**: ,Contrast  ,Feature

25 - **unique**: ,Contrast  ,Feature

26 - **dependency**: ,Contrast  ,Feature

27 - **introduced**: ,Contrast

28 - **constant**: ,Contrast

29 - **test**: ,Contrast

30 - **node**: ,Contrast  ,Feature

31 - **structures**: ,Contrast  ,Feature  ,Abstract

### mainpulating the section : 4

1 - **semantic**: ,Contrast  ,Feature

2 - **cases**: ,Contrast  ,Feature

3 - **advantages**: ,Contrast  ,Feature

4 - **treating**: ,Contrast  ,Feature

5 - **small**: ,Contrast  ,Feature

6 - **computation**: ,Contrast  ,Abstract

7 - **learned**: ,Contrast

8 - **sake**: ,Contrast

9 - **occur**: ,Contrast  ,Feature

10 - **information**: ,Contrast  ,Feature

11 - **feature**: ,Contrast  ,Feature  ,Abstract

12 - **representation**: ,Contrast  ,Feature

13 - **orders**: ,Contrast  ,Feature

14 - **tendencies**: ,Contrast  ,Feature

15 - **related**: ,Contrast

16 - **obtains**: ,Contrast

17 - **fails**: ,Contrast

18 - **kinds**: ,Contrast

19 - **achieved**: ,Contrast

20 - **depends**: ,Contrast

21 - **fail**: ,Contrast  ,Feature

22 - **efficiency**: ,Contrast  ,Feature  ,Abstract

23 - **applied**: ,Contrast  ,Feature

24 - **analysis**: ,Contrast  ,Feature  ,Abstract

25 - **sentence**: ,Contrast

26 - **unification**: ,Contrast  ,Feature  ,Abstract

27 - **unnecessary**: ,Contrast

28 - **agreements**: ,Contrast  ,Feature

29 - **rare**: ,Contrast

30 - **failure**: ,Contrast  ,Feature  ,Abstract

31 - **gain**: ,Contrast  ,Feature

### mainpulating the section : 5

1 - **graphs**: ,Contrast  ,Feature  ,Abstract

2 - **swapping**: ,Contrast  ,Feature  ,Abstract

3 - **total**: ,Contrast  ,Feature

4 - **Memory**: ,Contrast  ,Feature  ,Abstract

5 - **sharing**: ,Contrast  ,Feature

6 - **collection**: ,Contrast  ,Feature  ,Abstract

7 - **natural**: ,Contrast  ,Feature

8 - **generation**: ,Contrast  ,Feature  ,Abstract

9 - **methods**: ,Contrast  ,Feature  ,Abstract

10 - **language**: ,Contrast  ,Feature  ,Abstract

11 - **strategic**: ,Contrast  ,Feature

12 - **copies**: ,Contrast  ,Feature  ,Abstract

13 - **wastage**: ,Contrast  ,Feature

14 - **efficient**: ,Contrast  ,Feature  ,Abstract

15 - **access**: ,Contrast  ,Feature  ,Abstract

16 - **based**: ,Contrast  ,Feature

17 - **achieves**: ,Contrast  ,Feature

18 - **lazy**: ,Contrast  ,Feature  ,Abstract

19 - **tending**: ,Contrast  ,Feature

20 - **efficiency**: ,Contrast  ,Feature  ,Abstract

21 - **strategy**: ,Contrast  ,Feature  ,Abstract

22 - **treats**: ,Contrast  ,Feature

23 - **make**: ,Contrast  ,Feature

24 - **avoids**: ,Contrast  ,Feature

25 - **application**: ,Contrast  ,Feature

26 - **identical**: ,Contrast  ,Feature

27 - **unification**: ,Contrast  ,Feature  ,Abstract

28 - **reduces**: ,Contrast  ,Feature

29 - **page**: ,Contrast  ,Feature  ,Abstract

30 - **unification-based**: ,Contrast  ,Feature

31 - **ficos**: ,Contrast  ,Feature

32 - **introduces**: ,Contrast  ,Feature

33 - **garbage**: ,Contrast  ,Feature  ,Abstract

34 - **log**: ,Contrast  ,Feature

35 - **overhead**: ,Contrast  ,Feature

36 - **combined**: ,Contrast  ,Feature

37 - **incremental**: ,Contrast  ,Feature

### mainpulating the section : 6

##Total Features Number : 125 / 187

### mainpulating the section : 0

1 - **skeleton** ,Feature

2 - **information** ,Feature

3 - **natural** ,Feature

4 - **methods** ,Feature  ,Abstract

5 - **language** ,Feature  ,Abstract

6 - **systems** ,Feature  ,Abstract

7 - **part** ,Feature

8 - **based** ,Feature

9 - **strategy** ,Feature  ,Abstract

10 - **copying** ,Feature

11 - **proposed** ,Feature

12 - **inputs** ,Feature

13 - **unification** ,Feature  ,Abstract

14 - **processing** ,Feature

15 - **constraints** ,Feature

16 - **called** ,Feature

17 - **formalisms** ,Feature

18 - **structures** ,Feature  ,Abstract

### mainpulating the section : 1

1 - **represented** ,Feature

2 - **feature** ,Feature  ,Abstract

3 - **relationships** ,Feature

4 - **pairs** ,Feature

5 - **feature-value** ,Feature

6 - **ares** ,Feature

7 - **equal** ,Feature

8 - **greatest** ,Feature

9 - **directed** ,Feature

10 - **symbol** ,Feature

### mainpulating the section : 2

1 - **current** ,Feature

2 - **shared** ,Feature

3 - **meet** ,Feature

4 - **tile** ,Feature

5 - **contents** ,Feature

6 - **created** ,Feature

7 - **results** ,Feature

8 - **takes** ,Feature

9 - **arc** ,Feature

10 - **labels** ,Feature

11 - **subgraphs** ,Feature

12 - **treats** ,Feature

13 - **copied** ,Feature

14 - **values** ,Feature

15 - **procedure** ,Feature

16 - **inputs**: ,Contrast  ,Feature

17 - **node** ,Feature

### mainpulating the section : 3

1 - **consisting** ,Feature

2 - **erg** ,Feature

3 - **returns** ,Feature

4 - **newly** ,Feature

5 - **copies** ,Feature  ,Abstract

6 - **results**: ,Contrast  ,Feature

7 - **slots** ,Feature

8 - **arc**: ,Contrast  ,Feature

9 - **ares**: ,Contrast  ,Feature

10 - **definite** ,Feature

11 - **copied**: ,Contrast  ,Feature

12 - **procedure**: ,Contrast  ,Feature

13 - **adds** ,Feature

14 - **unique** ,Feature

15 - **dependency** ,Feature

16 - **node**: ,Contrast  ,Feature

17 - **structures**: ,Contrast  ,Feature  ,Abstract

### mainpulating the section : 4

1 - **semantic** ,Feature

2 - **cases** ,Feature

3 - **advantages** ,Feature

4 - **treating** ,Feature

5 - **small** ,Feature

6 - **occur** ,Feature

7 - **information**: ,Contrast  ,Feature

8 - **feature**: ,Contrast  ,Feature  ,Abstract

9 - **representation** ,Feature

10 - **orders** ,Feature

11 - **tendencies** ,Feature

12 - **fail** ,Feature

13 - **efficiency** ,Feature  ,Abstract

14 - **applied** ,Feature

15 - **analysis** ,Feature  ,Abstract

16 - **unification**: ,Contrast  ,Feature  ,Abstract

17 - **agreements** ,Feature

18 - **failure** ,Feature  ,Abstract

19 - **gain** ,Feature

### mainpulating the section : 5

1 - **graphs** ,Feature  ,Abstract

2 - **swapping** ,Feature  ,Abstract

3 - **total** ,Feature

4 - **Memory** ,Feature  ,Abstract

5 - **sharing** ,Feature

6 - **collection** ,Feature  ,Abstract

7 - **natural**: ,Contrast  ,Feature

8 - **generation** ,Feature  ,Abstract

9 - **methods**: ,Contrast  ,Feature  ,Abstract

10 - **language**: ,Contrast  ,Feature  ,Abstract

11 - **strategic** ,Feature

12 - **copies**: ,Contrast  ,Feature  ,Abstract

13 - **wastage** ,Feature

14 - **efficient** ,Feature  ,Abstract

15 - **access** ,Feature  ,Abstract

16 - **based**: ,Contrast  ,Feature

17 - **achieves** ,Feature

18 - **lazy** ,Feature  ,Abstract

19 - **tending** ,Feature

20 - **efficiency**: ,Contrast  ,Feature  ,Abstract

21 - **strategy**: ,Contrast  ,Feature  ,Abstract

22 - **treats**: ,Contrast  ,Feature

23 - **make** ,Feature

24 - **avoids** ,Feature

25 - **application** ,Feature

26 - **identical** ,Feature

27 - **unification**: ,Contrast  ,Feature  ,Abstract

28 - **reduces** ,Feature

29 - **page** ,Feature  ,Abstract

30 - **unification-based** ,Feature

31 - **ficos** ,Feature

32 - **introduces** ,Feature

33 - **garbage** ,Feature  ,Abstract

34 - **log** ,Feature

35 - **overhead** ,Feature

36 - **combined** ,Feature

37 - **incremental** ,Feature

### mainpulating the section : 6

#The Summary
**ze take 5 percent of the important and long sentences for making the summary**

Therefore , Pereira 's method needs relatively few new structures when two input FSs are difference in size and which input is larger are known before unification .

This method is called the strategic ij ! ~crementaI copy graph unification method ( the SING unification method ) .

Section 3 explains a TFS unification method based on Wroblewski 's method and then explains the problem with his method .

Once complex IeSs are extended as above , an atomic FS can be seen as an extended complex FS whose type symbol has only Top as its greater type symbol and only Bottom as its lesser type symbol and which has an empty set of feature value pairs .

t { however when a NODE has another NODE as its COPY value , the contents of the COPY value are used only when the COPY value is cub : rent .

The output node has been created only when neither input node is current ; or otherwise the output node is an existing current node .

Each arc value is copied and an arc with the same label and the copied value is added to the output node .

It then adds the arc copies and arcs of node that are not copied to the new node , and returns the new node ; ( 3 ) otherwise , CopyNode adds the pair consisting of the ancestor node node 2 and the are arc into the COPY- DEPENDENCY slot of node 1 '' and returns Nil_ .

FOR ALL arc IN nodes DO IF NotNIL ? ( new arc FindArc ( archangel new arcs ) THEN AddArc ( new node Newark undervalue .

For example , when unification of features for case markers does fail , treating these features first avoids treating features for semantic representations .


#analysing the annotation 1

##The Citing Sentences :

**Tomabechi** **avoids** these **problems** by **simulating** **non-destructiveness** without **incurring** the **overhead** necessary to support **backtracking** .

###The Corpus Reference Sentences :
1.0


**21** :
**itowever** , the problem with his method is that a **unitication** result **graph** **consists** only of **newly** **created** **structures** .

1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .


###Our Reference Sentences :
0.849409217824

**204** :
***structures*** ***sharing*** ***avoids*** ***Memory*** ***wastage*** ' .


0.862317722531

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.90399343983

**37** :
This causes O ( ***log*** d ) ***graphs*** ***node*** ***access*** **time** ***overhead*** in **assembling** the whole DG from the ***skeleton*** and **environment** where d is the number of ***node*** in the DG .


0.947615584444

**203** :
The **LING** ***unification*** ***methods*** ***achieves*** ***structures*** ***sharing*** without the os ( ***log*** d ) data ***access*** ***overhead*** of **Pereira** 's ***methods*** .


0.979808155903

**30** :
I ) **developing** a ***methods*** which ***avoids*** ***Memory*** ***wastage*** is very **important** .



##The Citing Sentences :

First , it **performs** a **destructive** ( but **reversible** ) **check** that the two **structures** are **compatible** , and only when that **succeeds** does it **produce** an **output** **structure** .

###The Corpus Reference Sentences :
0.146765400619


**21** :
**itowever** , the problem with his method is that a **unitication** result **graph** **consists** only of **newly** **created** **structures** .

1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .


###Our Reference Sentences :
0.0398990277212

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0492316983944

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.117221226682

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .


0.152245313242

**45** :
For example , when **constructing** a **phrase** ***structures*** from its ***part*** ( ***erg*** a **sentence** ***ficos*** a subject NP and VP ) , **unnecessary** **computation** can be **reduced** if the ***semantic*** ***representation*** is **assembled** after **checking** ***constraints*** such as **grammatical** ***agreements*** , which can ***fail*** .


0.232119474841

**38** :
**Avoiding** this problem in his ***methods*** **requires** a **special** **operation** of **merging** a **skeleton-environment** ***structures*** into a ***skeleton*** ***structures*** , but this **prevents** ***structures*** ***sharing*** .



##The Citing Sentences :

Thus , no **output** **structures** are **built** until it is certain that the **unification** will **ultimately** **succeed** .

###The Corpus Reference Sentences :
0.614025535919


**21** :
**itowever** , the problem with his method is that a **unitication** result **graph** **consists** only of **newly** **created** **structures** .

1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .


###Our Reference Sentences :
0.0398990277212

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0492316983944

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0645006489183

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0888310426895

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.117221226682

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .



##The Citing Sentences :

While an **improvement** over **simple** **destructive** **unification** , **Tomabechi** 's approach still **suffers** from what **Kogure** ( **Kogure** , 1990 ) **calls** **redundant** **copying** .

###The Corpus Reference Sentences :
1.0


**21** :
**itowever** , the problem with his method is that a **unitication** result **graph** **consists** only of **newly** **created** **structures** .

1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.861567642676


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .


###Our Reference Sentences :
0.0252829529723

**79** :
A ***unification*** example is shown in Fig .


0.0398990277212

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0492316983944

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0645006489183

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0888310426895

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .



##The Citing Sentences :

The new **feature** **structures** **produced** in the second phase of **unification** **include** **copies** of all the **substructures** of the **input** **graphs** , even when these **structures** are **unchanged** .

###The Corpus Reference Sentences :
0.480945600235


**21** :
**itowever** , the problem with his method is that a **unitication** result **graph** **consists** only of **newly** **created** **structures** .

0.762676985655


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .


###Our Reference Sentences :
0.0252829529723

**79** :
A ***unification*** example is shown in Fig .


0.0398990277212

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0492316983944

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0645006489183

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0888310426895

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .



##The Citing Sentences :

This can be **avoided** by **reusing** **parts** of the **input** **structures** in the **output** **structure** ( **Carroll** and **Malouf** , 1999 ) without **introducing** **significant** **bookkeeping** **overhead** .

###The Corpus Reference Sentences :
0.225932731565


**21** :
**itowever** , the problem with his method is that a **unitication** result **graph** **consists** only of **newly** **created** **structures** .

0.823217085377


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.846500733931


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .


###Our Reference Sentences :
0.0252829529723

**79** :
A ***unification*** example is shown in Fig .


0.0398990277212

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0492316983944

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0645006489183

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0883364869484

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .



#analysing the annotation 2

##The Citing Sentences :

In this **paper** , both these type **structures** and the type **symbol** **lattice** on which **term** **structures** are **definedare** **extended** to **treat** **negative** **descriptions** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0909529583632

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.210343473833

**63** :
An **extension** allows **complex** **FSs** to have type ***symbol*** which **define** a **lattice** ***structures*** on them , for example , as in [ **Pollard** and **Sag** 8 '' 11 .


0.231131051639

**72** :
Among such ***structures*** , ***unification*** c 'm be **defined** **IAP** , - **Kaci** 861 by using the following ***orders*** ; **ATFS** tl is less than or ***equal*** to a **TFS** t2 if and only if :  the type ***symbol*** of tl is less than or ***equal*** to the type ***symbol*** ; and  each of the ***feature*** of t2 **exists** in t1 and .


0.242741770745

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.282942421435

**65** :
An example of a type ***symbol*** **lattice** is shown in Fig .



##The Citing Sentences :

**Nega** **tions** of type **symbols** are **treated** by **extending** type **symbol** **lattices** , and **negations** of **feature** **existwicesand** **feature-address** **disagreements** are **treated** by ex **tending** **term** **structures** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0823964931995

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.0909529583632

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.0915568778016

**72** :
Among such ***structures*** , ***unification*** c 'm be **defined** **IAP** , - **Kaci** 861 by using the following ***orders*** ; **ATFS** tl is less than or ***equal*** to a **TFS** t2 if and only if :  the type ***symbol*** of tl is less than or ***equal*** to the type ***symbol*** ; and  each of the ***feature*** of t2 **exists** in t1 and .


0.131552380468

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.182658011188

**68** :
Once **complex** **IeSs** are **extended** as above , an **atomic** FS can be seen as an **extended** **complex** FS whose type ***symbol*** has only **Top** as its **greater** type ***symbol*** and only **Bottom** as its **lesser** type ***symbol*** and which has an **empty** set of ***feature*** ***values*** ***pairs*** .



##The Citing Sentences :

This **extension** can be seen as **intuitionistic** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0823964931995

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.0909529583632

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.0915568778016

**72** :
Among such ***structures*** , ***unification*** c 'm be **defined** **IAP** , - **Kaci** 861 by using the following ***orders*** ; **ATFS** tl is less than or ***equal*** to a **TFS** t2 if and only if :  the type ***symbol*** of tl is less than or ***equal*** to the type ***symbol*** ; and  each of the ***feature*** of t2 **exists** in t1 and .


0.131552380468

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.182658011188

**68** :
Once **complex** **IeSs** are **extended** as above , an **atomic** FS can be seen as an **extended** **complex** FS whose type ***symbol*** has only **Top** as its **greater** type ***symbol*** and only **Bottom** as its **lesser** type ***symbol*** and which has an **empty** set of ***feature*** ***values*** ***pairs*** .



##The Citing Sentences :

The **extension** is **classified** into **class** ( 1 ) **above.Based** on this **paper** 's **formalization** , **unification** al **gorithms** have been **developed** using **graph** **unificationtechniques** [ 23 , 16 ] .

###The Corpus Reference Sentences :
0.161297590087


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0823964931995

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.0869956898197

**79** :
A ***unification*** example is shown in Fig .


0.0909529583632

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.0915568778016

**72** :
Among such ***structures*** , ***unification*** c 'm be **defined** **IAP** , - **Kaci** 861 by using the following ***orders*** ; **ATFS** tl is less than or ***equal*** to a **TFS** t2 if and only if :  the type ***symbol*** of tl is less than or ***equal*** to the type ***symbol*** ; and  each of the ***feature*** of t2 **exists** in t1 and .


0.131552380468

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .



##The Citing Sentences :

**Programs** **based** on these **algo** **rithms** have been **implemented** in **Common** **Lisp** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0823964931995

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.0869956898197

**79** :
A ***unification*** example is shown in Fig .


0.0909529583632

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.0915568778016

**72** :
Among such ***structures*** , ***unification*** c 'm be **defined** **IAP** , - **Kaci** 861 by using the following ***orders*** ; **ATFS** tl is less than or ***equal*** to a **TFS** t2 if and only if :  the type ***symbol*** of tl is less than or ***equal*** to the type ***symbol*** ; and  each of the ***feature*** of t2 **exists** in t1 and .


0.131552380468

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .



##The Citing Sentences :

< /bodyText > < **sectionHeader** **confidence=** '' 0.650502 '' **genericHeader=** '' method '' >

###The Corpus Reference Sentences :
nan


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0823964931995

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.0869956898197

**79** :
A ***unification*** example is shown in Fig .


0.0909529583632

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .


0.0915568778016

**72** :
Among such ***structures*** , ***unification*** c 'm be **defined** **IAP** , - **Kaci** 861 by using the following ***orders*** ; **ATFS** tl is less than or ***equal*** to a **TFS** t2 if and only if :  the type ***symbol*** of tl is less than or ***equal*** to the type ***symbol*** ; and  each of the ***feature*** of t2 **exists** in t1 and .


0.131552380468

**64** :
The type ***symbol*** **lattice** contains the ***greatest*** type ***symbol*** **Top** , which **subsumes** every type ***symbol*** , and the least type ***symbol*** **Bottom** , which is **subsumed** by every **I.ype** ***symbol*** .



#analysing the annotation 3

##The Citing Sentences :

**Unification** of two **nodes** which have each other in their **dnodes** **yields** 1 because of **tag** **inconsistency** .

###The Corpus Reference Sentences :
0.562526067864


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.048335684946

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0514120512525

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0692431851305

**115** :
For example , the ***node*** Y ( **G3/** < os c G > ) will be **modified** to be the ***unification*** result of G 1/ < a c G > ( or **G1/** < b d > ) and **G2/** < b d > when the ***feature*** **paths** < b d > will be **treated** .


0.070637340919

**149** :
7 ) : ( 1 ) if ***node*** , the **dereference** result of ***node*** is ***current*** , then **CopyNode** ***returns*** ***node*** l '' to indicate that the **ancestor** ***node*** ***node*** 2 must be **coiffed** **immediately** ; ( 2 ) otherwise , **CopyArcs** is ***applied*** to ***node*** 1 and if it ***returns*** , ~ ; several ***arc*** ***copies*** , **CopyNode** **creates** a new ***copies*** ***node*** .


0.0715269255473

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .



##The Citing Sentences :

These **computations** **require** **negligible** **additional** **computation** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.048335684946

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0514120512525

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0692431851305

**115** :
For example , the ***node*** Y ( **G3/** < os c G > ) will be **modified** to be the ***unification*** result of G 1/ < a c G > ( or **G1/** < b d > ) and **G2/** < b d > when the ***feature*** **paths** < b d > will be **treated** .


0.070637340919

**149** :
7 ) : ( 1 ) if ***node*** , the **dereference** result of ***node*** is ***current*** , then **CopyNode** ***returns*** ***node*** l '' to indicate that the **ancestor** ***node*** ***node*** 2 must be **coiffed** **immediately** ; ( 2 ) otherwise , **CopyArcs** is ***applied*** to ***node*** 1 and if it ***returns*** , ~ ; several ***arc*** ***copies*** , **CopyNode** **creates** a new ***copies*** ***node*** .


0.0715269255473

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .



##The Citing Sentences :

To **simplify** the **explanation** , the **destructive** **version** of **graph** **unification** is used above .

###The Corpus Reference Sentences :
0.155928492193


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.048335684946

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0514120512525

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0692431851305

**115** :
For example , the ***node*** Y ( **G3/** < os c G > ) will be **modified** to be the ***unification*** result of G 1/ < a c G > ( or **G1/** < b d > ) and **G2/** < b d > when the ***feature*** **paths** < b d > will be **treated** .


0.070637340919

**149** :
7 ) : ( 1 ) if ***node*** , the **dereference** result of ***node*** is ***current*** , then **CopyNode** ***returns*** ***node*** l '' to indicate that the **ancestor** ***node*** ***node*** 2 must be **coiffed** **immediately** ; ( 2 ) otherwise , **CopyArcs** is ***applied*** to ***node*** 1 and if it ***returns*** , ~ ; several ***arc*** ***copies*** , **CopyNode** **creates** a new ***copies*** ***node*** .


0.0715269255473

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .



##The Citing Sentences :

Other **versions** **based** on more **efficient** **graph** **unification** **methods** such as **Wroblewski** 's and **Kogure** 's method [ 23 , 16 ) have also been **developed** .

###The Corpus Reference Sentences :
0.335341741213


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.048335684946

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0514120512525

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0548303888044

**52** :
These two ***methods*** can be ***combined*** into a **single** ***methods*** ***called*** the ***strategic*** ***lazy*** **ijAcremeatal** ***copies*** ***graphs*** ***unification*** ***methods*** ( the **SLING** ***unification*** ***methods*** ) .


0.0600188175854

**51** :
This ***methods*** is ***called*** the ***strategic*** ij ! ~crementaI ***copies*** ***graphs*** ***unification*** ***methods*** ( the **SING** ***unification*** ***methods*** ) .


0.0688759804257

**207** :
The **SING** ***unification*** ***methods*** ***introduces*** the **concept** of ***feature*** ***unification*** ***strategy*** .



##The Citing Sentences :

Furthermore , it is **easy** to **modify** other **graph** **unification** **inethods** [ 21 , 61 to allow **augmented** 1TSs .

###The Corpus Reference Sentences :
0.155427465932


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.048335684946

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0514120512525

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0548303888044

**52** :
These two ***methods*** can be ***combined*** into a **single** ***methods*** ***called*** the ***strategic*** ***lazy*** **ijAcremeatal** ***copies*** ***graphs*** ***unification*** ***methods*** ( the **SLING** ***unification*** ***methods*** ) .


0.0600188175854

**51** :
This ***methods*** is ***called*** the ***strategic*** ij ! ~crementaI ***copies*** ***graphs*** ***unification*** ***methods*** ( the **SING** ***unification*** ***methods*** ) .


0.0688759804257

**207** :
The **SING** ***unification*** ***methods*** ***introduces*** the **concept** of ***feature*** ***unification*** ***strategy*** .



##The Citing Sentences :

This **paper** has **proposed** an **augmentation** of **feature** **structures** ( **FSs** ) which **introduces** **negative** in **formation** into **FSs** in **unification-based** **formalisms.Unification-based** **linguistic** **formalisms** use **lbs** to **describe** **linguistic** **objects** and **phenomena** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.048335684946

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0514120512525

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0548303888044

**52** :
These two ***methods*** can be ***combined*** into a **single** ***methods*** ***called*** the ***strategic*** ***lazy*** **ijAcremeatal** ***copies*** ***graphs*** ***unification*** ***methods*** ( the **SLING** ***unification*** ***methods*** ) .


0.0600188175854

**51** :
This ***methods*** is ***called*** the ***strategic*** ij ! ~crementaI ***copies*** ***graphs*** ***unification*** ***methods*** ( the **SING** ***unification*** ***methods*** ) .


0.0688759804257

**207** :
The **SING** ***unification*** ***methods*** ***introduces*** the **concept** of ***feature*** ***unification*** ***strategy*** .



#analysing the annotation 4

##The Citing Sentences :

Accordingly , for example , a **compleX** , **ion** **argument** for **cases** where an **inactive** **edge** is in the **chart** is as follows .

###The Corpus Reference Sentences :
1.0


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .

1.0


**206** :
This **reduces** repeated **calculation** of **substructures** .


###Our Reference Sentences :
0.371930571614

**57** :
**Ordinary** **FSs** used in ***unification-based*** **grammar** ***formalisms*** such as **PAT** ] . { [ **Shieher** 851 ***arc*** **classified** into two **classes** , namely , **atomic** leSs and **complex** **FSs** .


0.375341521614

**195** :
However , such ***cases*** do not ***occur*** in **practice** .


0.529027278958

**60** :
**complex** **FSs** can have **complex** **FSs** as their ***feature*** ***values*** and can **share** certain ***values*** among ***feature*** .


0.584529902134

**69** :
**extended** **complex** **FSs** are ***called*** **typed** ***feature*** ***structures*** ( **TFSs** ) .


0.595066811569

**59** :
**complex** **FSs** are used to **partially** **describe** **objects** by specifying ***values*** for certain ***feature*** or **attributes** of described **objects** .



##The Citing Sentences :

`` **membe** , ' ( [ a ~ -- b 7 , i , j , a , el , **Cache** ) , **member** ( [ b , - , j , k , fl , f ] , **Chart** ) , **unify** ( e , [ b : f ] , g ) Is , ~ ~'°'2~ ~t~ **rnember** ( [ a + -- 7 , i , k , **ctb** , g ] , **Agenda** ) **Isn+** , where e , f and g are **feature** **structures** , and .unify ( x , y , z ) **means** that z is the result of **unifying** x and y . **Feature** **structures** **uniformly** **represent** various **lingtlistic** **constraints** such as **subcategorizations** , **gaps** , **unbounded** **dependencies** , and **logical** **forms** .

###The Corpus Reference Sentences :
0.698103528045


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .

1.0


**206** :
This **reduces** repeated **calculation** of **substructures** .


###Our Reference Sentences :
0.174911461778

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.251060402382

**69** :
**extended** **complex** **FSs** are ***called*** **typed** ***feature*** ***structures*** ( **TFSs** ) .


0.266292328269

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.306266283093

**182** :
For example , when ***unification*** of ***feature*** for ***cases*** **markers** does ***fail*** , ***treating*** these ***feature*** first ***avoids*** ***treating*** ***feature*** for ***semantic*** ***representation*** .


0.357427099801

**60** :
**complex** **FSs** can have **complex** **FSs** as their ***feature*** ***values*** and can **share** certain ***values*** among ***feature*** .



##The Citing Sentences :

A problem of this **representation** scheme is that it **describes** all possible **constraints** in one **structure** and **deals** with them at once .

###The Corpus Reference Sentences :
0.588803893479


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .

1.0


**206** :
This **reduces** repeated **calculation** of **substructures** .


###Our Reference Sentences :
0.038736740906

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0438365096995

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.117893508779

**45** :
For example , when **constructing** a **phrase** ***structures*** from its ***part*** ( ***erg*** a **sentence** ***ficos*** a subject NP and VP ) , **unnecessary** **computation** can be **reduced** if the ***semantic*** ***representation*** is **assembled** after **checking** ***constraints*** such as **grammatical** ***agreements*** , which can ***fail*** .


0.130854498369

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .


0.174911461778

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .



##The Citing Sentences :

This is **inefficient** with many **copy** **operations** **due** to **unfications** of **unnecessary** **features** that do not **contribute** to **successful** **unification** [ 6 ] .

###The Corpus Reference Sentences :
0.477663748239


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .

1.0


**206** :
This **reduces** repeated **calculation** of **substructures** .


###Our Reference Sentences :
0.038736740906

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0438365096995

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0760288864862

**181** :
In such ***cases*** , ***application*** of the **EFF** ***strategy*** , that is , ***treating*** ***feature*** ***tending*** to **fall** in ***unification*** first , ***reduces*** **unnecessary** **computation** when the ***unification*** **finally** **fails** .


0.0772753396467

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .


0.0773813213327

**201** :
Moreover , it is possible for each type ***symbol*** to **select** whether to **apply** ***feature*** ***unification*** ***orders*** **sorting** or not .



##The Citing Sentences :

Thus **treatments** such as **strategic** **unification** [ 6 ] have been **developed** .

###The Corpus Reference Sentences :
0.276998694424


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .

1.0


**206** :
This **reduces** repeated **calculation** of **substructures** .


###Our Reference Sentences :
0.0234427104629

**79** :
A ***unification*** example is shown in Fig .


0.038736740906

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0438365096995

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0760288864862

**181** :
In such ***cases*** , ***application*** of the **EFF** ***strategy*** , that is , ***treating*** ***feature*** ***tending*** to **fall** in ***unification*** first , ***reduces*** **unnecessary** **computation** when the ***unification*** **finally** **fails** .


0.0772753396467

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .



##The Citing Sentences :

It seems that a **preferable** approach is to **treat** **linguistic** **constraints** **piecew'ise** , **taking** into consider > **tion** **abductivity** of **parsing** , **uniform** **integration** of various **linguistic** **proc~ssings** , and the problem of a **unificat.ion-based** approach .

###The Corpus Reference Sentences :
1.0


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .

1.0


**206** :
This **reduces** repeated **calculation** of **substructures** .


###Our Reference Sentences :
0.0234427104629

**79** :
A ***unification*** example is shown in Fig .


0.038736740906

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0438365096995

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0760288864862

**181** :
In such ***cases*** , ***application*** of the **EFF** ***strategy*** , that is , ***treating*** ***feature*** ***tending*** to **fall** in ***unification*** first , ***reduces*** **unnecessary** **computation** when the ***unification*** **finally** **fails** .


0.0772753396467

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .



##The Citing Sentences :

From this point of **view** , we **describe** such **treatments** as , especially , **incorporation** of **word** **properties** , case **analyses** , **composition** of **logical** **forms** , and **interpretMon** of **noun** **phrases** with **adnominal** **particles** .

###The Corpus Reference Sentences :
1.0


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .

1.0


**206** :
This **reduces** repeated **calculation** of **substructures** .


###Our Reference Sentences :
0.0234427104629

**79** :
A ***unification*** example is shown in Fig .


0.038736740906

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0438365096995

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0760288864862

**181** :
In such ***cases*** , ***application*** of the **EFF** ***strategy*** , that is , ***treating*** ***feature*** ***tending*** to **fall** in ***unification*** first , ***reduces*** **unnecessary** **computation** when the ***unification*** **finally** **fails** .


0.0772753396467

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .



#analysing the annotation 5

##The Citing Sentences :

If , however , the type or **template** **calls** are **processed** on **demand** at **run** **time** , as it needs to be the case in **FTFs** with **recursive** **types** , these **names** can be **treated** as **regular** **conjuncts** .

###The Corpus Reference Sentences :
1.0


**3** :
The other , **called** **ti~e** **strategic** **incremental** **copy** **graph** **unification** method , uses an **early** **failure** finding **strategy** which first tries to **unify** ; **ubstructures** **tending** to **fail** in **unification** ; this method is ; **based** on **stochastic** data on **tim** **likelihood** of **failure** and , 'educes **unnecessary** **computation** .


###Our Reference Sentences :
0.799263091752

**37** :
This causes O ( ***log*** d ) ***graphs*** ***node*** ***access*** **time** ***overhead*** in **assembling** the whole DG from the ***skeleton*** and **environment** where d is the number of ***node*** in the DG .


0.897210509349

**14** :
**Japanese** ***analysis*** ***systems*** ***based*** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS ***unification*** .


0.94077597684

**39** :
This **paper** **proposes** an FS ***unification*** ***methods*** that allows ***structures*** ***sharing*** with **constant** **moder** ***node*** ***access*** **time** .


0.969946649138

**109** :
For example , consider the ***cases*** when ***feature*** a is first **treated** at the **roots** ***node*** of G1 and G2 in Fig .


0.970920955089

**115** :
For example , the ***node*** Y ( **G3/** < os c G > ) will be **modified** to be the ***unification*** result of G 1/ < a c G > ( or **G1/** < b d > ) and **G2/** < b d > when the ***feature*** **paths** < b d > will be **treated** .



##The Citing Sentences :

If a **conjunction** is **unified** with some other **feature** **term** , every **conjunct** has to be **unified** .

###The Corpus Reference Sentences :
1.0


**3** :
The other , **called** **ti~e** **strategic** **incremental** **copy** **graph** **unification** method , uses an **early** **failure** finding **strategy** which first tries to **unify** ; **ubstructures** **tending** to **fail** in **unification** ; this method is ; **based** on **stochastic** data on **tim** **likelihood** of **failure** and , 'educes **unnecessary** **computation** .


###Our Reference Sentences :
0.190806149201

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.212595770632

**182** :
For example , when ***unification*** of ***feature*** for ***cases*** **markers** does ***fail*** , ***treating*** these ***feature*** first ***avoids*** ***treating*** ***feature*** for ***semantic*** ***representation*** .


0.231097482994

**60** :
**complex** **FSs** can have **complex** **FSs** as their ***feature*** ***values*** and can **share** certain ***values*** among ***feature*** .


0.233198918675

**69** :
**extended** **complex** **FSs** are ***called*** **typed** ***feature*** ***structures*** ( **TFSs** ) .


0.249029555854

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .



##The Citing Sentences :

**Controlling** the order in which **operands** are **processed** in **conjunctions** may **save** **time** if **conjuncts** can be **processed** first that are most likely to **fail** .

###The Corpus Reference Sentences :
0.83961049853


**3** :
The other , **called** **ti~e** **strategic** **incremental** **copy** **graph** **unification** method , uses an **early** **failure** finding **strategy** which first tries to **unify** ; **ubstructures** **tending** to **fail** in **unification** ; this method is ; **based** on **stochastic** data on **tim** **likelihood** of **failure** and , 'educes **unnecessary** **computation** .


###Our Reference Sentences :
0.190806149201

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.212595770632

**182** :
For example , when ***unification*** of ***feature*** for ***cases*** **markers** does ***fail*** , ***treating*** these ***feature*** first ***avoids*** ***treating*** ***feature*** for ***semantic*** ***representation*** .


0.231097482994

**60** :
**complex** **FSs** can have **complex** **FSs** as their ***feature*** ***values*** and can **share** certain ***values*** among ***feature*** .


0.233198918675

**69** :
**extended** **complex** **FSs** are ***called*** **typed** ***feature*** ***structures*** ( **TFSs** ) .


0.249029555854

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .



##The Citing Sentences :

This **observation** is the **basis** for a **reordering** method **proposed** by **Kogure** [ 1990 ] .

###The Corpus Reference Sentences :
1.0


**3** :
The other , **called** **ti~e** **strategic** **incremental** **copy** **graph** **unification** method , uses an **early** **failure** finding **strategy** which first tries to **unify** ; **ubstructures** **tending** to **fail** in **unification** ; this method is ; **based** on **stochastic** data on **tim** **likelihood** of **failure** and , 'educes **unnecessary** **computation** .


###Our Reference Sentences :
0.190806149201

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.212595770632

**182** :
For example , when ***unification*** of ***feature*** for ***cases*** **markers** does ***fail*** , ***treating*** these ***feature*** first ***avoids*** ***treating*** ***feature*** for ***semantic*** ***representation*** .


0.231097482994

**60** :
**complex** **FSs** can have **complex** **FSs** as their ***feature*** ***values*** and can **share** certain ***values*** among ***feature*** .


0.233198918675

**69** :
**extended** **complex** **FSs** are ***called*** **typed** ***feature*** ***structures*** ( **TFSs** ) .


0.249029555854

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .



##The Citing Sentences :

If , e.g. , in **syntactic** **rule** **applications** , the value of the **attribute** **agreement** in the **representation** of **nominal** **elements** **leads** to **clashes** more often than the value of the **attribute** **definiteneness** , it would in **general** be more **efficient** to **unify** **agreement** before **definiteness** .

###The Corpus Reference Sentences :
1.0


**3** :
The other , **called** **ti~e** **strategic** **incremental** **copy** **graph** **unification** method , uses an **early** **failure** finding **strategy** which first tries to **unify** ; **ubstructures** **tending** to **fail** in **unification** ; this method is ; **based** on **stochastic** data on **tim** **likelihood** of **failure** and , 'educes **unnecessary** **computation** .


###Our Reference Sentences :
0.190806149201

**76** :
U_ **Bottom** **Figure** 1 : **Exainple** of a type ***symbol*** **lattice** -- 2 -- **peSymb°10** ***feature*** ] ] ] I ***feature*** 2 I ***feature*** 3 **Tag** T **ypeSymbol3** ] ] ***feature*** 4 l [ .feature 5 **TIeature3** 7Tag ( a ) ***feature-value*** **matrices** **notation** `` ? '' i~ the **prefix** for a **Tag** and **TFSs** with the same **Tag** are **token-identical** .


0.212595770632

**182** :
For example , when ***unification*** of ***feature*** for ***cases*** **markers** does ***fail*** , ***treating*** these ***feature*** first ***avoids*** ***treating*** ***feature*** for ***semantic*** ***representation*** .


0.231097482994

**60** :
**complex** **FSs** can have **complex** **FSs** as their ***feature*** ***values*** and can **share** certain ***values*** among ***feature*** .


0.233198918675

**69** :
**extended** **complex** **FSs** are ***called*** **typed** ***feature*** ***structures*** ( **TFSs** ) .


0.249029555854

**196** :
( 2 ) Number of ***feature*** F have : if each F has only a ***small*** number of ***feature*** , the ***efficiency*** ***gain*** from the **SING** ***unification*** ***methods*** is ***small*** .



##The Citing Sentences :

Every **unification** **failure** in **processing** **cuts** off some **unsuccessful** **branch** in the **search** **tree** .

###The Corpus Reference Sentences :
0.201841541118


**3** :
The other , **called** **ti~e** **strategic** **incremental** **copy** **graph** **unification** method , uses an **early** **failure** finding **strategy** which first tries to **unify** ; **ubstructures** **tending** to **fail** in **unification** ; this method is ; **based** on **stochastic** data on **tim** **likelihood** of **failure** and , 'educes **unnecessary** **computation** .


###Our Reference Sentences :
0.0716181831604

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.123360799751

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.132033313887

**183** :
The **SING** ***unification*** ***methods*** uses this ***failure*** ***tendencies*** ***information*** .


0.146661106088

**184** :
These ***unification*** ***failure*** ***tendencies*** **depend** on ***systems*** such as ***analysis*** ***systems*** or ***generation*** ***systems*** .


0.153964592346

**79** :
A ***unification*** example is shown in Fig .



#analysing the annotation 6

##The Citing Sentences :

Some **unifications** with **conjuncts** **build** a **lot** of **structure** whereas others do not .

###The Corpus Reference Sentences :
1.0


**186** :
in this method , **theretbre** , the **failure** **tendency** **information** is **acquired** by a **learning** process .

0.37776072255


**187** :
That is , the **SING** **unification** method **applied** in an **analysis** system uses the **failure** **tendency** **information** **acquired** by a **learning** **analysis** process .

0.371522724584


**188** :
in the **learning** process , when FS **unification** is **applied** , **feature** treatment **orders** are **randomized** for the **sake** of **random** **extraction** .


###Our Reference Sentences :
0.0574887939823

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0820015515269

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.135231693579

**79** :
A ***unification*** example is shown in Fig .


0.218571257223

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.227876983945

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .



##The Citing Sentences :

However , the **failure** **potential** , as it is **defined** here , may **depend** on the **processing** scheme and on the order of **subterms** in the **grammar** .

###The Corpus Reference Sentences :
0.306033597124


**186** :
in this method , **theretbre** , the **failure** **tendency** **information** is **acquired** by a **learning** process .

0.583201749617


**187** :
That is , the **SING** **unification** method **applied** in an **analysis** system uses the **failure** **tendency** **information** **acquired** by a **learning** **analysis** process .

1.0


**188** :
in the **learning** process , when FS **unification** is **applied** , **feature** treatment **orders** are **randomized** for the **sake** of **random** **extraction** .


###Our Reference Sentences :
0.0574887939823

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0820015515269

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.135231693579

**79** :
A ***unification*** example is shown in Fig .


0.218571257223

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.227876983945

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .



##The Citing Sentences :

If , e.g. , the value of the **agreement** **feature** **person** in the **definition** of the type **Verb** **leads** to **failure** more often than the value of the **feature** number , this may **simply** be **due** to the order in which the two **subterms** are **processed** .

###The Corpus Reference Sentences :
0.674759705288


**186** :
in this method , **theretbre** , the **failure** **tendency** **information** is **acquired** by a **learning** process .

0.804659728154


**187** :
That is , the **SING** **unification** method **applied** in an **analysis** system uses the **failure** **tendency** **information** **acquired** by a **learning** **analysis** process .

0.308729482623


**188** :
in the **learning** process , when FS **unification** is **applied** , **feature** treatment **orders** are **randomized** for the **sake** of **random** **extraction** .


###Our Reference Sentences :
0.0574887939823

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0820015515269

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.135231693579

**79** :
A ***unification*** example is shown in Fig .


0.218571257223

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.227876983945

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .



##The Citing Sentences :

**Assume** the unlikely situation that the value of number would have **led** to **failure-if** the order had been **reversed-in** all the **cases** in which the value of **person** did in the oM order .

###The Corpus Reference Sentences :
1.0


**186** :
in this method , **theretbre** , the **failure** **tendency** **information** is **acquired** by a **learning** process .

1.0


**187** :
That is , the **SING** **unification** method **applied** in an **analysis** system uses the **failure** **tendency** **information** **acquired** by a **learning** **analysis** process .

1.0


**188** :
in the **learning** process , when FS **unification** is **applied** , **feature** treatment **orders** are **randomized** for the **sake** of **random** **extraction** .


###Our Reference Sentences :
0.055467133451

**195** :
However , such ***cases*** do not ***occur*** in **practice** .


0.0574887939823

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0820015515269

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.135231693579

**79** :
A ***unification*** example is shown in Fig .


0.218571257223

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .



##The Citing Sentences :

Thus for any **automatic** **counting** scheme some **constant** **shuffling** and **reshuffling** of the **conjunct** order needs to be **applied** until the order **stabilizes** ( see also [ **Kogure** 1990 ] ) .

###The Corpus Reference Sentences :
1.0


**186** :
in this method , **theretbre** , the **failure** **tendency** **information** is **acquired** by a **learning** process .

0.873944894706


**187** :
That is , the **SING** **unification** method **applied** in an **analysis** system uses the **failure** **tendency** **information** **acquired** by a **learning** **analysis** process .

0.872681182306


**188** :
in the **learning** process , when FS **unification** is **applied** , **feature** treatment **orders** are **randomized** for the **sake** of **random** **extraction** .


###Our Reference Sentences :
0.055467133451

**195** :
However , such ***cases*** do not ***occur*** in **practice** .


0.0574887939823

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0820015515269

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.135231693579

**79** :
A ***unification*** example is shown in Fig .


0.218571257223

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .



##The Citing Sentences :

There is a second **criterion** to consider .

###The Corpus Reference Sentences :
nan


**186** :
in this method , **theretbre** , the **failure** **tendency** **information** is **acquired** by a **learning** process .

nan


**187** :
That is , the **SING** **unification** method **applied** in an **analysis** system uses the **failure** **tendency** **information** **acquired** by a **learning** **analysis** process .

nan


**188** :
in the **learning** process , when FS **unification** is **applied** , **feature** treatment **orders** are **randomized** for the **sake** of **random** **extraction** .


###Our Reference Sentences :
0.055467133451

**195** :
However , such ***cases*** do not ***occur*** in **practice** .


0.0574887939823

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0820015515269

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.135231693579

**79** :
A ***unification*** example is shown in Fig .


0.218571257223

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .



#analysing the annotation 7

##The Citing Sentences :

The point here is that the **parser** tries to **combine** the result **_18** of this step more than once with different other **structures** , but **unification** is a **destructive** **operation** !

###The Corpus Reference Sentences :
0.394684900879


**39** :
This **paper** **proposes** an FS **unification** method that allows **structure** **sharing** with **constant** **m'der** **node** **access** **time** .

0.209509282417


**40** :
This method **achieves** **structure** **sharing** by **introducing** **lazy** **copying** to **Wroblewski** 's **incremental** **copy** **graph** **unification** method .

0.179240100449


**78** :
Then , the **unification** of tl **anti** t2 is **defined** as their **greatest** **lower** **bound** or the **meet** .


###Our Reference Sentences :
0.0646940814426

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0803913741116

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.141842653952

**79** :
A ***unification*** example is shown in Fig .


0.224545105264

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.229711382366

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .



##The Citing Sentences :

So , instead of **directly** **unifying** the **structures** of say _7 and **_18** ( **_11** and **_18** , . . ) , _7 and **_18** are **inherited** into the new **structure** of **_20** .

###The Corpus Reference Sentences :
0.58644941672


**39** :
This **paper** **proposes** an FS **unification** method that allows **structure** **sharing** with **constant** **m'der** **node** **access** **time** .

0.475571273886


**40** :
This method **achieves** **structure** **sharing** by **introducing** **lazy** **copying** to **Wroblewski** 's **incremental** **copy** **graph** **unification** method .

1.0


**78** :
Then , the **unification** of tl **anti** t2 is **defined** as their **greatest** **lower** **bound** or the **meet** .


###Our Reference Sentences :
0.03351980845

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0336461446797

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0646940814426

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0803913741116

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.0940940794095

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .



##The Citing Sentences :

This way **virtual** **copies** of the **structures** are **produced** , and these are **unified** It is **essential** for **efficiency** that a **virtual** **copy** does not mean that the **structure** of the type has to be **copied** .

###The Corpus Reference Sentences :
0.682714095947


**39** :
This **paper** **proposes** an FS **unification** method that allows **structure** **sharing** with **constant** **m'der** **node** **access** **time** .

0.391987123304


**40** :
This method **achieves** **structure** **sharing** by **introducing** **lazy** **copying** to **Wroblewski** 's **incremental** **copy** **graph** **unification** method .

1.0


**78** :
Then , the **unification** of tl **anti** t2 is **defined** as their **greatest** **lower** **bound** or the **meet** .


###Our Reference Sentences :
0.03351980845

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0336461446797

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0646940814426

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0803913741116

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.0940940794095

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .



##The Citing Sentences :

The **lazy** **copying** approach ( [ **Kogure** , 1990 ] , and [ **Emele** , 1991 ] for **lazy** **copying** in **TFS** with **historical** **backtracking** ) **copies** only **overlapping** **parts** of the **structure** .

###The Corpus Reference Sentences :
0.803574469975


**39** :
This **paper** **proposes** an FS **unification** method that allows **structure** **sharing** with **constant** **m'der** **node** **access** **time** .

0.437747528718


**40** :
This method **achieves** **structure** **sharing** by **introducing** **lazy** **copying** to **Wroblewski** 's **incremental** **copy** **graph** **unification** method .

1.0


**78** :
Then , the **unification** of tl **anti** t2 is **defined** as their **greatest** **lower** **bound** or the **meet** .


###Our Reference Sentences :
0.03351980845

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0336461446797

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0646940814426

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0803913741116

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.0940940794095

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .



##The Citing Sentences :

**CFS** **avoids** even this by **structure-** and **constraint-sharing** .

###The Corpus Reference Sentences :
1.0


**39** :
This **paper** **proposes** an FS **unification** method that allows **structure** **sharing** with **constant** **m'der** **node** **access** **time** .

1.0


**40** :
This method **achieves** **structure** **sharing** by **introducing** **lazy** **copying** to **Wroblewski** 's **incremental** **copy** **graph** **unification** method .

1.0


**78** :
Then , the **unification** of tl **anti** t2 is **defined** as their **greatest** **lower** **bound** or the **meet** .


###Our Reference Sentences :
0.03351980845

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0336461446797

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0646940814426

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0803913741116

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.0940940794095

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .



##The Citing Sentences :

For **common** **sentences** in **German** , which **tend** to be rather **long** , a **lot** of **types** will be **generated** They **supply** only a **small** **part** of **structure** themselves ( just the **path** from the **functor** to the **filler** and a **simple** **slot-filler** **combination** **structure** ) .

###The Corpus Reference Sentences :
0.607839098591


**39** :
This **paper** **proposes** an FS **unification** method that allows **structure** **sharing** with **constant** **m'der** **node** **access** **time** .

0.502695800049


**40** :
This method **achieves** **structure** **sharing** by **introducing** **lazy** **copying** to **Wroblewski** 's **incremental** **copy** **graph** **unification** method .

1.0


**78** :
Then , the **unification** of tl **anti** t2 is **defined** as their **greatest** **lower** **bound** or the **meet** .


###Our Reference Sentences :
0.03351980845

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0336461446797

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0577421801587

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0646940814426

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.0686771137821

**45** :
For example , when **constructing** a **phrase** ***structures*** from its ***part*** ( ***erg*** a **sentence** ***ficos*** a subject NP and VP ) , **unnecessary** **computation** can be **reduced** if the ***semantic*** ***representation*** is **assembled** after **checking** ***constraints*** such as **grammatical** ***agreements*** , which can ***fail*** .



#analysing the annotation 8

##The Citing Sentences :

19901 .

###The Corpus Reference Sentences :
nan


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
1.0

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


1.0

**5** :
Various **kinds** of **grammatical** ***formalisms*** without t , **transformation** were ***proposed*** from the **late** 1970s I ; **rough** the 1980s l ( ] **aider** al 85 , l ( **plan** and **Bresnan** 82 , **Kay** 1~5 , **Pollm** 'd and **Sag** 871 .


1.0

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


1.0

**7** :
These ***formalisms*** were ***applied*** in the field of ***natural*** ***language*** ***processing*** and , ***based*** on these ***formalisms*** , ~ : ***systems*** such as **machine** **translation** ***systems*** were **developed** [ l < ol ; u , e et a l 8gJ .


1.0

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .



##The Citing Sentences :

and **eliminated** Over **Copying** and **Early** **Copying** ( as **defined** in [ **Tomabechi** , 1991 ] 2 ) and **ralt** about twice the **speed** of [ **Wroblewski** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.251864739973

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


0.290303978748

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.381499575204

**23** :
***copying*** **sharable** ***part*** is ***called*** **redundant** ***copying*** .


0.607545407481

**29** :
***Memory*** is **wasted** by such **redundant** ***copying*** and this causes **frequent** ***garbage*** ***collection*** and ***page*** ***swapping*** which **decrease** the ***total*** ***systems*** ***efficiency*** .


0.741478251828

**20** :
**Ile** ***proposed*** an ***incremental*** ***copies*** ***graphs*** ***unification*** ***methods*** to **avoid** over ***copying*** and **early** ***copying*** .



##The Citing Sentences :

1987 ] 's **algorithm** , a In this **pal** ) er we **proi** ) **ose** another **design** principle f ( n ' **graph** **unification** **bmsed** upon yet another **accepted** **observation** that : **Unmodified** **subgraphs** can be **shared** .

###The Corpus Reference Sentences :
0.170242218317


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0967327360366

**79** :
A ***unification*** example is shown in Fig .


0.170242218317

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.183782526222

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.209581984948

**28** :
In **Kasper** 's **disjunctive** ***feature*** **description** ***unification*** [ **Kasper** 861 , such ***cases*** ***occur*** very **frequently** in **unifying** ***definite*** and **disjunct** 's ***definite*** ***part*** .


0.217751118567

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .



##The Citing Sentences :

At **lemst** two **schelnes** have been **proposed** **recently** ] ) **a.~ed** Ul ) OU this **observation** ( namely [ **Kogure** .

###The Corpus Reference Sentences :
1.0


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0967327360366

**79** :
A ***unification*** example is shown in Fig .


0.170242218317

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.183782526222

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.209581984948

**28** :
In **Kasper** 's **disjunctive** ***feature*** **description** ***unification*** [ **Kasper** 861 , such ***cases*** ***occur*** very **frequently** in **unifying** ***definite*** and **disjunct** 's ***definite*** ***part*** .


0.217751118567

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .



##The Citing Sentences :

1990 ] and [ **Emele** , 1991 ] ) ; however , both **schemes** are I ) **ased** upon the **increlllent'al** **Col** ) **yiug** **sehellle** all ( l ~-LS ( [ e- **scribed** in [ **Tomal** ) **eehi** , 1991 ] **incremental** **copying** **schemes** **inherently** **suffcr** **fi'om** **Early** **Copying** as **defined** in that article .

###The Corpus Reference Sentences :
0.761104800408


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0967327360366

**79** :
A ***unification*** example is shown in Fig .


0.170242218317

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.183782526222

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.209581984948

**28** :
In **Kasper** 's **disjunctive** ***feature*** **description** ***unification*** [ **Kasper** 861 , such ***cases*** ***occur*** very **frequently** in **unifying** ***definite*** and **disjunct** 's ***definite*** ***part*** .


0.217751118567

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .



##The Citing Sentences :

This is I ) **eeause** , when a **unification** **falls** , the **copies** that were ( : **reated** up to the point of **failure** are **w~Lste** ( l if **copies** are **created** **increment** ; **ally** , By way of **definition** we would like to **categorize** the **sharing** of **struetul'eS** in **gral** ) hs into **Feature-** **Structure** **Sharing** ( **FS-Sharing** ) ~nd **Data-Structure** **Sharing** ( **DS-Sharing** ) .

###The Corpus Reference Sentences :
0.345074274128


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0967327360366

**79** :
A ***unification*** example is shown in Fig .


0.170242218317

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.183782526222

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.203882565086

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.209581984948

**28** :
In **Kasper** 's **disjunctive** ***feature*** **description** ***unification*** [ **Kasper** 861 , such ***cases*** ***occur*** very **frequently** in **unifying** ***definite*** and **disjunct** 's ***definite*** ***part*** .



##The Citing Sentences :

Below **arc** our **definitions** :  **Feature-Structure** **Sharing** : Two or more **distinct** i ) ~ , **ths** within a **graph** **share** the same **sub-graph** by ( : **onwwging** ( 111 the same **node** **equivalent** to the **notion** of **structure** **sharing** or **reenlrancy** in **linguistic** **theories** ( such ~ in [ **Pollard** and **Sag** , 1987 ] ) .

###The Corpus Reference Sentences :
0.926629150838


**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


###Our Reference Sentences :
0.0311465848199

**148** :
The **revised** **CopyNode** ***procedure*** ***takes*** as its ***inputs*** the ***node*** to be ***copied*** ***node*** I and the ***arc*** ***arc*** I with ***node*** I as its ***values*** and ***node*** 2 as its immediate **ancestor** ***node*** ( **ire** the ***arc*** 's **initial** ***node*** ) , and does the following ( set Fig .


0.0327160849553

**149** :
7 ) : ( 1 ) if ***node*** , the **dereference** result of ***node*** is ***current*** , then **CopyNode** ***returns*** ***node*** l '' to indicate that the **ancestor** ***node*** ***node*** 2 must be **coiffed** **immediately** ; ( 2 ) otherwise , **CopyArcs** is ***applied*** to ***node*** 1 and if it ***returns*** , ~ ; several ***arc*** ***copies*** , **CopyNode** **creates** a new ***copies*** ***node*** .


0.0349009856026

**171** :
**ENDIF** **ENDPROCEDURE** **CopyArcs** ***procedure*** **AlcsCopied** ( ***node*** ) new ***arc*** O- FOR ALL ***arc*** IN ***node*** DO new ***node*** **CopyNode** ( **overvalue** ***arc*** , ***node*** ) .


0.042740385125

**150** :
It then ***adds*** the ***arc*** ***copies*** and ***arc*** of ***node*** that ***ares*** not ***copied*** to the new ***node*** , and ***returns*** the new ***node*** ; ( 3 ) otherwise , **CopyNode** ***adds*** the ***pairs*** ***consisting*** of the **ancestor** ***node*** ***node*** 2 and the ***ares*** ***arc*** into the **COPY-** ***dependency*** ***slots*** of ***node*** 1 '' and ***returns*** **Nil_** .


0.047367495911

**142** :
With such a ***methods*** , it is possible to **delay** ***copying*** a ***node*** until either its own ***contents*** need to change ( ***erg*** ***node*** **G3/Ka** c ! 7 > ) or until it is **found** to have an ***arc*** ( **sequence** ) to a ***node*** t , **hat** needs to be ***copied*** ( ***erg*** ***node*** X **G3/** < a c > in Fig .



#analysing the annotation 9
**Not valid annotation**

#analysing the annotation 10

##The Citing Sentences :

**Earley** 's **algorithm** , 2 .

###The Corpus Reference Sentences :
1.0


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .


###Our Reference Sentences :
0.951612831425

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


1.0

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


1.0

**5** :
Various **kinds** of **grammatical** ***formalisms*** without t , **transformation** were ***proposed*** from the **late** 1970s I ; **rough** the 1980s l ( ] **aider** al 85 , l ( **plan** and **Bresnan** 82 , **Kay** 1~5 , **Pollm** 'd and **Sag** 871 .


1.0

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


1.0

**7** :
These ***formalisms*** were ***applied*** in the field of ***natural*** ***language*** ***processing*** and , ***based*** on these ***formalisms*** , ~ : ***systems*** such as **machine** **translation** ***systems*** were **developed** [ l < ol ; u , e et a l 8gJ .



##The Citing Sentences :

**active** **chartparsing** , 3 .

###The Corpus Reference Sentences :
nan


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .


###Our Reference Sentences :
0.951612831425

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


1.0

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


1.0

**5** :
Various **kinds** of **grammatical** ***formalisms*** without t , **transformation** were ***proposed*** from the **late** 1970s I ; **rough** the 1980s l ( ] **aider** al 85 , l ( **plan** and **Bresnan** 82 , **Kay** 1~5 , **Pollm** 'd and **Sag** 871 .


1.0

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


1.0

**7** :
These ***formalisms*** were ***applied*** in the field of ***natural*** ***language*** ***processing*** and , ***based*** on these ***formalisms*** , ~ : ***systems*** such as **machine** **translation** ***systems*** were **developed** [ l < ol ; u , e et a l 8gJ .



##The Citing Sentences :

**generalized** LR **parsing** .

###The Corpus Reference Sentences :
1.0


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .


###Our Reference Sentences :
0.745935050293

**139** :
In Section 5 , a ***methods*** which uses this **generalized** ***strategy*** is ***proposed*** .


0.916166667196

**138** :
This ***orders*** ***strategy*** can be **generalized** to the **EFF** and ***applied*** to the **ordering** of ***arc*** with **common** ***labels*** .


0.951612831425

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


1.0

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


1.0

**5** :
Various **kinds** of **grammatical** ***formalisms*** without t , **transformation** were ***proposed*** from the **late** 1970s I ; **rough** the 1980s l ( ] **aider** al 85 , l ( **plan** and **Bresnan** 82 , **Kay** 1~5 , **Pollm** 'd and **Sag** 871 .



##The Citing Sentences :

2In the **large-scale** **HPSG-based** **spoken** **Japanese** **analysis** system **developed** at **ATR** , sometimes 98 percent of the **elapsed** **time** is **devoted** to **graph** **unification** ( [ **Kogure** , 1990 ] ) .

###The Corpus Reference Sentences :
0.349240459607


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .


###Our Reference Sentences :
0.12101960535

**79** :
A ***unification*** example is shown in Fig .


0.192552579392

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.205728818209

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.224030485369

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.225904681478

**14** :
**Japanese** ***analysis*** ***systems*** ***based*** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS ***unification*** .



##The Citing Sentences :

**ATR** **Interpreting** **Telephony** Research **Laboratories*** **Seikacho** , **Sorakugun** , **Kyoto** 61902 **JAPAN** **grow** so **quickly** .

###The Corpus Reference Sentences :
nan


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .


###Our Reference Sentences :
0.12101960535

**79** :
A ***unification*** example is shown in Fig .


0.192552579392

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.205728818209

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.224030485369

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.225904681478

**14** :
**Japanese** ***analysis*** ***systems*** ***based*** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS ***unification*** .



##The Citing Sentences :

Thus , it **makes** **sense** to **speed** up the **unification** **operations** to **improve** the **total** **speed** **performance** of the **natural** **language** **systems** .

###The Corpus Reference Sentences :
0.304885750211


**205** :
Furthermore , **structure** **sharing** **increases** the **portion** of **token** **identical** **substructures** of **FSs** which **makes** it **efficient** to keep **unification** **results** of **substructures** of **FSs** and **reuse** them .


###Our Reference Sentences :
0.0723138314898

**79** :
A ***unification*** example is shown in Fig .


0.0857054604945

**14** :
**Japanese** ***analysis*** ***systems*** ***based*** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS ***unification*** .


0.0997586976247

**42** :
In a ***natural*** ***language*** ***processing*** ***systems*** that uses **declarative** ***constraints*** **rules** in **terms** of **FSs** , FS ***unification*** provides **constraint-checking** and **structure-** **building** **mechanisms** .


0.12101960535

**79** :
A ***unification*** example is shown in Fig .


0.161716923518

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .



#analysing the annotation 11

##The Citing Sentences :

Since our **algorithm** is **essentially** **parallel** , **patallelization** is one **logical** **choice** to **pursue** further **speedup** .

###The Corpus Reference Sentences :
1.0


**11** :
For example , a **spoken** **Present** .

1.0


**14** :
**Japanese** **analysis** system **based** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS **unification** .


###Our Reference Sentences :
0.951612831425

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


1.0

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


1.0

**5** :
Various **kinds** of **grammatical** ***formalisms*** without t , **transformation** were ***proposed*** from the **late** 1970s I ; **rough** the 1980s l ( ] **aider** al 85 , l ( **plan** and **Bresnan** 82 , **Kay** 1~5 , **Pollm** 'd and **Sag** 871 .


1.0

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


1.0

**7** :
These ***formalisms*** were ***applied*** in the field of ***natural*** ***language*** ***processing*** and , ***based*** on these ***formalisms*** , ~ : ***systems*** such as **machine** **translation** ***systems*** were **developed** [ l < ol ; u , e et a l 8gJ .



##The Citing Sentences :

**Parallel** **processes** can be **continuously** **created** as **unifyl** **reeurses** **deeper** and **deeper** without **creating** any **copies** by **simply** looking for a possible **failure** of the **unification** ( and **preparing** for **successive** **copying** in **ease** **unification** **succeeds** ) .

###The Corpus Reference Sentences :
1.0


**11** :
For example , a **spoken** **Present** .

0.157020818431


**14** :
**Japanese** **analysis** system **based** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS **unification** .


###Our Reference Sentences :
0.144788187663

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.145358041059

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.200441726438

**183** :
The **SING** ***unification*** ***methods*** uses this ***failure*** ***tendencies*** ***information*** .


0.213916635631

**184** :
These ***unification*** ***failure*** ***tendencies*** **depend** on ***systems*** such as ***analysis*** ***systems*** or ***generation*** ***systems*** .


0.220644500833

**79** :
A ***unification*** example is shown in Fig .



##The Citing Sentences :

So far , we have **completed** a **preliminary** **implementation** on a **shared** **memory** **parallel** **hardware** with about 75 percent of **effective** **parallelization** rate .

###The Corpus Reference Sentences :
1.0


**11** :
For example , a **spoken** **Present** .

1.0


**14** :
**Japanese** **analysis** system **based** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS **unification** .


###Our Reference Sentences :
0.144788187663

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.145358041059

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.200441726438

**183** :
The **SING** ***unification*** ***methods*** uses this ***failure*** ***tendencies*** ***information*** .


0.213916635631

**184** :
These ***unification*** ***failure*** ***tendencies*** **depend** on ***systems*** such as ***analysis*** ***systems*** or ***generation*** ***systems*** .


0.220644500833

**79** :
A ***unification*** example is shown in Fig .



##The Citing Sentences :

With the **simplicity** of our **algorithm** and the **ease** of **implementing** it ( **compared** to both **incremental** **copying** **schemes** and **lazy** **schemes** ) , **combined** with the **demonstrated** **speed** of the **algorithm** , the **algorithm** could be a **viable** **alternative** to **existing** **unification** **algorithms** used in **current** ~That is , unless some new scheme for **reducing** **excessive** **copying** is **introduced** such as **scucture-sharing** of an **unchanged** **shared-forest** ( [ **Kogure** , 1990 ] ) .

###The Corpus Reference Sentences :
1.0


**11** :
For example , a **spoken** **Present** .

0.197078068008


**14** :
**Japanese** **analysis** system **based** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS **unification** .


###Our Reference Sentences :
0.144788187663

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.145358041059

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.147602314882

**79** :
A ***unification*** example is shown in Fig .


0.181242287229

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.200441726438

**183** :
The **SING** ***unification*** ***methods*** uses this ***failure*** ***tendencies*** ***information*** .



##The Citing Sentences :

Even then , our **criticism** of the **cost** of **delaying** **evaluation** would still be **valid** .

###The Corpus Reference Sentences :
1.0


**11** :
For example , a **spoken** **Present** .

1.0


**14** :
**Japanese** **analysis** system **based** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS **unification** .


###Our Reference Sentences :
0.144788187663

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.145358041059

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.147602314882

**79** :
A ***unification*** example is shown in Fig .


0.181242287229

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.200441726438

**183** :
The **SING** ***unification*** ***methods*** uses this ***failure*** ***tendencies*** ***information*** .



##The Citing Sentences :

Also , although different in **methodology** from the way **suggested** by **Kogure** for **Wroblewski** 's **algorithm** , it is possible to **at~in** **structure-sharing** of an **unchanged** **forest** in our scheme as well .

###The Corpus Reference Sentences :
1.0


**11** :
For example , a **spoken** **Present** .

1.0


**14** :
**Japanese** **analysis** system **based** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS **unification** .


###Our Reference Sentences :
0.144788187663

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.145358041059

**194** :
The ***efficiency*** of the **SING** ***unification*** ***methods*** **depends** on the following **factors** : ( 1 ) The overall F ***unification*** ***failure*** rate of the process : in **extreme** ***cases*** , if Go ***unification*** ***failure*** **occurs** , the ***methods*** has no ***advantages*** except the ***overhead*** of ***feature*** ***unification*** ***orders*** **sorting** .


0.147602314882

**79** :
A ***unification*** example is shown in Fig .


0.181242287229

**0** :
**Strategic** **Lazy** **Incremental** **Copy** **Graph** **Unification**


0.200441726438

**183** :
The **SING** ***unification*** ***methods*** uses this ***failure*** ***tendencies*** ***information*** .



#analysing the annotation 12

##The Citing Sentences :

Although the **overhead** for this **copying** is **significant** , it is **impossible** to **represent** a **resul.-taut** **unitied** **graph** without **creating** any new **strut** **tures** .

###The Corpus Reference Sentences :
0.981018570031


**203** :
The **LING** **unification** method **achieves** **structure** **sharing** without the O ( **log** d ) data **access** **overhead** of **Pereira** 's method .

0.463337961679


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.728661926612


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.572547952114


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.240274192999

**37** :
This causes O ( ***log*** d ) ***graphs*** ***node*** ***access*** **time** ***overhead*** in **assembling** the whole DG from the ***skeleton*** and **environment** where d is the number of ***node*** in the DG .


0.279234781281

**22** :
This is **unnecessary** because there are often ***inputs*** ***subgraphs*** that can be used as ***part*** of the result ***graphs*** without any **modification** , or as **sharable** ***part*** between one of the ***inputs*** ***graphs*** and the result ***graphs*** .


0.415576167617

**81** :
In ***tile*** ***directed*** ***graphs*** **notation** , **TFS** ***unification*** **corresponds** to ***graphs*** **merging** .


0.435928872105

**25** :
The **redundantly** ***copied*** ***part*** are relatively **large** when ***inputs*** ***graphs*** have few **common** ***feature*** **paths** .


0.464565005763

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .



##The Citing Sentences :

**Unnecessary** **copying** , though , must be **identified** and **minimized** .

###The Corpus Reference Sentences :
1.0


**203** :
The **LING** **unification** method **achieves** **structure** **sharing** without the O ( **log** d ) data **access** **overhead** of **Pereira** 's method .

0.99001414643


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.408195651049


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.0677018608237


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.0579555142501

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.188858720035

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


0.240274192999

**37** :
This causes O ( ***log*** d ) ***graphs*** ***node*** ***access*** **time** ***overhead*** in **assembling** the whole DG from the ***skeleton*** and **environment** where d is the number of ***node*** in the DG .


0.275543993136

**23** :
***copying*** **sharable** ***part*** is ***called*** **redundant** ***copying*** .


0.279234781281

**22** :
This is **unnecessary** because there are often ***inputs*** ***subgraphs*** that can be used as ***part*** of the result ***graphs*** without any **modification** , or as **sharable** ***part*** between one of the ***inputs*** ***graphs*** and the result ***graphs*** .



##The Citing Sentences :

**Wroblewski** ( 1987 ) **delined** two **kinds** of **unnecessary** **copying-** **over-copying** ( **copying** **structures** not **needed** to **represent** **resultant** **graphs** ) and **early-copying** ( **copying** **structures** even though **unitication** **fails** ) -but this **account** is **flawed** because the **resultant** **graph** is **assumed** to **consist** only of **newly** **created** **structures** even if **parts** of the **inputs** that are not **changed** during **mtitication** could be **shared** with the **resultant** **graph** .

###The Corpus Reference Sentences :
0.498027518649


**203** :
The **LING** **unification** method **achieves** **structure** **sharing** without the O ( **log** d ) data **access** **overhead** of **Pereira** 's method .

0.398364568723


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.72722647557


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.773637055262


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.0579555142501

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.188858720035

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


0.240274192999

**37** :
This causes O ( ***log*** d ) ***graphs*** ***node*** ***access*** **time** ***overhead*** in **assembling** the whole DG from the ***skeleton*** and **environment** where d is the number of ***node*** in the DG .


0.245710170695

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.275543993136

**23** :
***copying*** **sharable** ***part*** is ***called*** **redundant** ***copying*** .



##The Citing Sentences :

A more **eNcient** **unification** **algorithm** would **avoid** this **redundant** **copying** ( **copying** **structures** that can be **shared** by the **input** and **resultant** **graphs** ) ( **Kogure** , 1990 ) .

###The Corpus Reference Sentences :
0.16541118536


**203** :
The **LING** **unification** method **achieves** **structure** **sharing** without the O ( **log** d ) data **access** **overhead** of **Pereira** 's method .

0.685603936872


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.819020944877


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.763885734885


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.0579555142501

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.171028446722

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.188858720035

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


0.192588273881

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .


0.239406044594

**79** :
A ***unification*** example is shown in Fig .



##The Citing Sentences :

To **distinguish** **structure** **sharing** at the **implementation** level **fl'om** that at the **logical** **lew'l** ( that is , **coreference** **relations** between **feature-addresses** ) , the **lbrmer** is **called** **data-structure** **sharing** and the latter is **called** **feature-structure** **sharing** ( **Tomabechi** , 1992 ) .

###The Corpus Reference Sentences :
0.407628391588


**203** :
The **LING** **unification** method **achieves** **structure** **sharing** without the O ( **log** d ) data **access** **overhead** of **Pereira** 's method .

1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.899129171124


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.0579555142501

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.114317616738

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.171028446722

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.188858720035

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


0.192588273881

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .



##The Citing Sentences :

' [ 'he **key** **approaches** to **reducing** the **amount** of **structures** **copied** are **lazy** **copying** and **data-structure** **sharing** .

###The Corpus Reference Sentences :
0.535247910508


**203** :
The **LING** **unification** method **achieves** **structure** **sharing** without the O ( **log** d ) data **access** **overhead** of **Pereira** 's method .

1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.821485785726


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.718777886511


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.0579555142501

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.11047314699

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.114317616738

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.171028446722

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.174076986484

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .



#analysing the annotation 13

##The Citing Sentences :

The **link** is **meaningflfl** during only one **unification** process and thus **enables** **nondestructive** **modification** .

###The Corpus Reference Sentences :
0.999102190341


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.000818137139739

**79** :
A ***unification*** example is shown in Fig .


0.0971114215184

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.12565042903

**28** :
In **Kasper** 's **disjunctive** ***feature*** **description** ***unification*** [ **Kasper** 861 , such ***cases*** ***occur*** very **frequently** in **unifying** ***definite*** and **disjunct** 's ***definite*** ***part*** .


0.157841409915

**199** :
In such ***cases*** , the **SING** ***unification*** ***methods*** **obtains** **efl** ] ***efficiency*** ***gain*** .


0.17039723806

**14** :
**Japanese** ***analysis*** ***systems*** ***based*** on **llPSG** [ **Kogure** 891 uses 90 % - 98 % of the **elapsed** **time** in FS ***unification*** .



##The Citing Sentences :

4 Using an **idea** **similar** to **Karttunen** 's , **Tomabechi** ( 1991 ) **proposed** a **quasi-destructive** **unification** that uses **node** **structures** with **fields** for **keeping** **update** **information** that **survives** only during the **unification** process .

###The Corpus Reference Sentences :
1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.000818137139739

**79** :
A ***unification*** example is shown in Fig .


0.0686125547337

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0967054131362

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0971114215184

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.109443856043

**149** :
7 ) : ( 1 ) if ***node*** , the **dereference** result of ***node*** is ***current*** , then **CopyNode** ***returns*** ***node*** l '' to indicate that the **ancestor** ***node*** ***node*** 2 must be **coiffed** **immediately** ; ( 2 ) otherwise , **CopyArcs** is ***applied*** to ***node*** 1 and if it ***returns*** , ~ ; several ***arc*** ***copies*** , **CopyNode** **creates** a new ***copies*** ***node*** .



##The Citing Sentences :

5 **Unification** **algorithms** **allowing** **data-structure** **sharing** ( **DSS** **unification** **algorithms** ) are **based** on two **approaches** : the **Boyer** and **Moore** approach , which was **originally** **developed** for **term** **unification** in **theorem-proving** ( **Boyer** & **Moore** , 1972 ) and was **adopted** by **Pereira** ( 1985 ) ; and the **lazy** **copying** **suggested** by **Karttnnen** ~nd **Kay** ( 1985 ) .

###The Corpus Reference Sentences :
1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.924247526719


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.880663448988


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.000818137139739

**79** :
A ***unification*** example is shown in Fig .


0.0686125547337

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0967054131362

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0971114215184

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.101450869852

**79** :
A ***unification*** example is shown in Fig .



##The Citing Sentences :

**Recent** **lazy** **copying** **unification** **algorithms** are **based** on **Wroblewski** 's or **Tomabeehi** 's **schema** : **Godden** ( 1990 ) **proposed** a **unification** **algorithm** that uses **active** data **structures** , **Kogure** ( 1990 ) **proposed** a **lazy** **incremental** **copy** **graph** ( **LING** ) **unification** that uses **dependency-directed** **eol** ) **yiug** , and **Emeie** ( 1991 ) **proposed** a **lazy-incremental** **copying** ( **LIC** ) **unification** that uses **chronological** **dereference** .

###The Corpus Reference Sentences :
0.881338340005


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

0.897425637836


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.863379150414


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.000818137139739

**79** :
A ***unification*** example is shown in Fig .


0.0686125547337

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0967054131362

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0971114215184

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .


0.101450869852

**79** :
A ***unification*** example is shown in Fig .



##The Citing Sentences :

These **algorithms** are b0 , **sed** on **Wroblewski** 's **algorithm** , and **Tomabechi** ( 1992 ) has **proposed** a **data-structure-sharing** **version** of his **quasi-destructive** **unification** .

###The Corpus Reference Sentences :
1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.000818137139739

**79** :
A ***unification*** example is shown in Fig .


0.00466305450002

**79** :
A ***unification*** example is shown in Fig .


0.0686125547337

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0967054131362

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .


0.0971114215184

**135** :
This ***orders*** is **related** to the ***unification*** ***failure*** ***tendencies*** .



##The Citing Sentences :

3.2 The **Structure** **Sharing** Problem .

###The Corpus Reference Sentences :
1.0


**22** :
This is **unnecessary** because there are often **input** **snbgraphs** that can be used as **part** of the result **graph** without any **modification** , or as **sharable** **parts** between one of the **input** **graphs** and the result **graph** .

1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.000818137139739

**79** :
A ***unification*** example is shown in Fig .


0.00466305450002

**79** :
A ***unification*** example is shown in Fig .


0.0652243930848

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0686125547337

**116** :
***incremental*** ***copies*** ***graphs*** ***unification*** ***procedure*** **Unify** ( ***node*** 1 ***node*** 2 ***node*** 1 **dereference** ( ***node*** .


0.0967054131362

**88** :
When a ***node*** ***node*** 1 has a ***node*** ***node*** 2 as its **FORWARD** ***values*** , the other ***contents*** of ***tile*** ***node*** 1 are ignored and **tim** ***contents*** of ***node*** 2 are used .



#analysing the annotation 14

##The Citing Sentences :

Only those **copies** are **destructively** **modified** .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.326383115924

**175** :
**ENDPROCEDURE** **Figure** 7 : The **revised** **CopyNode** ***procedure*** has the **disadvantages** of ***treating*** ***copies*** ***dependency*** ***information*** .


0.42650405623

**156** :
In the above **explanation** , both **COPY-DEPENDENCY** and ***copies*** ***slots*** ***ares*** used for the **sake** of **simplicity** .


0.437888867411

**144** :
To **achieve** this , I , he **LING** ***unification*** ***methods*** , which uses ***copies*** ***dependency*** ***information*** , was **developed** .


0.452119209772

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .


0.549995947308

**145** :
The **LING** ***unification*** ***procedure*** uses a **revised** **CopyNode** ***procedure*** which does not ***copies*** ***structures*** **immediately** .



##The Citing Sentences :

**Finally** , the **copy** of the **newly** **constructed** **root** will be **returned** in case of **success** , and all the **copy** **pointers** will be **invalidated** in **constant** **time** by **increment-** **ing** a **global** **generation** **counter** without **traversing** the **arguments** again , **leaving** the **arguments** **unchanged** .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.326383115924

**175** :
**ENDPROCEDURE** **Figure** 7 : The **revised** **CopyNode** ***procedure*** has the **disadvantages** of ***treating*** ***copies*** ***dependency*** ***information*** .


0.413039269702

**175** :
**ENDPROCEDURE** **Figure** 7 : The **revised** **CopyNode** ***procedure*** has the **disadvantages** of ***treating*** ***copies*** ***dependency*** ***information*** .


0.42650405623

**156** :
In the above **explanation** , both **COPY-DEPENDENCY** and ***copies*** ***slots*** ***ares*** used for the **sake** of **simplicity** .


0.437888867411

**144** :
To **achieve** this , I , he **LING** ***unification*** ***methods*** , which uses ***copies*** ***dependency*** ***information*** , was **developed** .


0.452119209772

**19** :
**Wroblewski** **claims** that ***copying*** is **wrong** when an **algorithm** ***copies*** too much ( over ***copying*** ) or ***copies*** too soon ( **early** ***copying*** ) .



##The Citing Sentences :

**Redundant** **Copying** A problem **arises** with **Wroblewski** 's **account** , because the **resulting** DG **consists** only of **newly** **created** **structures** even if **parts** of the **input** **DGs** that are not **changed** could be **shared** with the **resultant** DG .

###The Corpus Reference Sentences :
0.60224382731


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.721732278056


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.113924741937

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.17960659037

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.224522496322

**45** :
For example , when **constructing** a **phrase** ***structures*** from its ***part*** ( ***erg*** a **sentence** ***ficos*** a subject NP and VP ) , **unnecessary** **computation** can be **reduced** if the ***semantic*** ***representation*** is **assembled** after **checking** ***constraints*** such as **grammatical** ***agreements*** , which can ***fail*** .


0.260168798323

**177** :
Usually , the number of ***feature*** in two ***inputs*** ***structures*** is relatively ***small*** and the **size** of the two ***inputs*** ***structures*** ***ares*** often very different .


0.307894585623

**38** :
**Avoiding** this problem in his ***methods*** **requires** a **special** **operation** of **merging** a **skeleton-environment** ***structures*** into a ***skeleton*** ***structures*** , but this **prevents** ***structures*** ***sharing*** .



##The Citing Sentences :

A better method would **avoid** ( **eliminate** ) such **redundant** **copying** as it is **called** by [ **Kogure** 90 ] .

###The Corpus Reference Sentences :
0.289560149342


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.206547232216


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.113924741937

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.17960659037

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.201289396691

**23** :
***copying*** **sharable** ***part*** is ***called*** **redundant** ***copying*** .


0.206578361588

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .


0.224522496322

**45** :
For example , when **constructing** a **phrase** ***structures*** from its ***part*** ( ***erg*** a **sentence** ***ficos*** a subject NP and VP ) , **unnecessary** **computation** can be **reduced** if the ***semantic*** ***representation*** is **assembled** after **checking** ***constraints*** such as **grammatical** ***agreements*** , which can ***fail*** .



##The Citing Sentences :

**Structure** **Sharing** The **concept** of **structure** **sharing** has been **introduced** to **minimize** the **amount** of **copying** by **allowing** **DGs** to **share** **common** **parts** of their **structure** .

###The Corpus Reference Sentences :
0.739280904299


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.814152282129


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.113924741937

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.129717443762

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.17960659037

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.201289396691

**23** :
***copying*** **sharable** ***part*** is ***called*** **redundant** ***copying*** .


0.206578361588

**18** :
**Previous** research **identified** DG ***copying*** as a **significant** ***overhead*** .



##The Citing Sentences :

The **Boyer** and **Moore** approach uses a **skeleton/environment** **representation** for **structure** **sharing** .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**24** :
A better method would **nfinimize** the **copying** of **sharable** **varts** .


###Our Reference Sentences :
0.0711391839304

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.107490713471

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.113924741937

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.129717443762

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.17960659037

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .



#analysing the annotation 15

##The Citing Sentences :

This **holds** , in particular , if it **takes** much more **time** to **create** new **structures** than to **update** old **reclaimed** **structures** .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.137494148448


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

1.0


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.0379395419538

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0453956201011

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.110258417037

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .


0.145558751798

**45** :
For example , when **constructing** a **phrase** ***structures*** from its ***part*** ( ***erg*** a **sentence** ***ficos*** a subject NP and VP ) , **unnecessary** **computation** can be **reduced** if the ***semantic*** ***representation*** is **assembled** after **checking** ***constraints*** such as **grammatical** ***agreements*** , which can ***fail*** .


0.230038004754

**38** :
**Avoiding** this problem in his ***methods*** **requires** a **special** **operation** of **merging** a **skeleton-environment** ***structures*** into a ***skeleton*** ***structures*** , but this **prevents** ***structures*** ***sharing*** .



##The Citing Sentences :

**Comparison** with other **Approaches** **Karttunen** 's **Reversible** **Unification** [ **Karttunen** 86 ] does not use **structure** **sharing** at M1 .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.512830173332


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

1.0


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.0379395419538

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0453956201011

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0893802893865

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.110258417037

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .


0.113063615419

**8** :
In such ***unification-based*** ***formalisms*** , ***feature*** ***structures*** FS ) ***unification*** is the most **fundamental** and **significant** **operation** .



##The Citing Sentences :

A new DG is **copied** from the **modified** **arguments** after **successful** **unification** , and the **argument** **DGs** are then **restored** to their **original** state by **undoing** all the changes **made** during **unification** hence **requiring** a second **pass** through the DG to **assemble** the result and **adding** a **constant** **time** for the **save** **operation** before each **modification** .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.992530929268


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.0301834073706

**79** :
A ***unification*** example is shown in Fig .


0.0379395419538

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0453956201011

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0893802893865

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.110258417037

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .



##The Citing Sentences :

As it has been **noticed** by [ **Godden** 90 ] and [ **Kogure** 90 ] , the **key** **idea** of **avoiding** `` **redundant** **copying** '' is to do **copying** **lazily** .

###The Corpus Reference Sentences :
0.302470976916


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.618418208581


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.904450401827


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.0301834073706

**79** :
A ***unification*** example is shown in Fig .


0.0379395419538

**6** :
These ***formalisms*** were **developed** relatively **independentIy** but actually had **common** **properties** ; **theft** is , they used data ***structures*** ***called*** **frictional** ***structures*** or ***feature*** ***structures*** and they were ***based*** on **underneath** **operation** on these data ***structures*** .


0.0453956201011

**27** :
I '' or example , in **unifying** an FS **representing** ***constraints*** on **phrase** ***structures*** and an FS **representing** a **daughter** **phrase** ***structures*** , such **eases** ***occur*** very **frequent** ly .


0.0893802893865

**53** :
Section 2 **explains** **typed** ***feature*** ***structures*** ( **TFSs** ) and ***unification*** on them .


0.110258417037

**10** :
**Tiffs** ***dependency*** is especially **crucial** for **lexicon-driven** **approaches** such as **tlPSO** [ **Pollard** and **Sag** 861 and **JPSG** [ **Gunji** 871 because **rich** **lexicon** ***information*** and **phrase** ***structures*** ***information*** is described in **terms** of **FSs** .



##The Citing Sentences :

**Copying** of **nodes** will be **delayed** until a **destructive** change is about to take **place** .

###The Corpus Reference Sentences :
0.907748268508


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.953982912164


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.164663058831


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

**Godden** uses **active** data **structures** ( **Lisp** **closures** ) to **implement** **lazy** **evaluation** of **copying** , and **Kogure** uses a **revised** **copynode** **procedure** which **maintains** **copy** **dependency** **information** in order to **avoid** immediate **copying** .

###The Corpus Reference Sentences :
0.769792431336


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.357743229603


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.967806334505


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

327 ~ .

###The Corpus Reference Sentences :
nan


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

nan


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

nan


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

**procedure** **unify** ( **nodel** , **node2** : **CopyNode** ) **nodel** * -- **deref** ( **nodel** ) **node2** ~-deter ( **node2** ) IF **node1** = **node2** THEN **return** ( **nodel** ) ELSE **newtype** ~-nodel.type A **node2.type** IF **newtype** = I THEN **return** ( l ) ELSE < **SharedArcsl** , **SharedArcs2** > ~-SharedArcs ( **nodel** , **node2** ) < **UniqueArcsl** , **UniqueArcs2** > ~-UniqueArcs ( **nodel** , **node2** ) IF **ActiveP** ( **nodel** ) THEN **node** ~-nodel **node.arcs** ~-node.arcs U **UniqueArcs2** **node2.copy** ~-node ELSE IF **ActiveP** ( **node2** ) THEN **node** ~-node2 **node.arcs** ~-node.arcs LJ **UniqueArcsl** **nodel** , **copy** *- **node** ELSE **node** ~-CreateCopyNode **nodel.copy** *- **node** **node2.copy** ~-node **node.arcs** ~-UniqueArcsl U **SharedArcsl** U **UniqueArcs2** **ENDIF** **ENDIF** **node.type** ~-newtype FOR EACH < **SharedArcl** , **SharedArc2** > IN < **SharedArcsl** , **SharedArcs2** > DO **unify** ( **SharedArcl.dest** , **SharedArc2.dest** ) **return** ( **node** ) **ENDIF** **ENDIF** **END** **unify** **Figure** 4 : The **unification** **procedure** approach **naive** **Pereira** 85 **Karttunen/Kay** 85 **Karttunen** 86 **Wroblewski** 87 **Godden** 90 **Kogure** 90 **LIC** **methods** **early** over **redundant** **incr** .

###The Corpus Reference Sentences :
0.99874855454


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.114788216841


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

**lazy** **copying** **copying** **copying** **copying** **copying** yes yes yes no no no no no no no no no yes no yes no no yes no no no yes yes yes no no no yes no yes no yes yes no yes no yes no yes yes **Figure** 5 : **Comparison** of **unification** **approaches** **structure** **sharing** no yes yes no no yes yes yes Both of these **approaches** **suffer** from **difficulties** of their own .

###The Corpus Reference Sentences :
0.672791621791


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.347711996234


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.938956968481


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

In **Godden** 's case , **part** of the **copying** is **substituted/traded** for by the **creation** of **active** data **structures** ( **Lisp** **closures** ) , a **potentially** very **costly** **operation** , even where it would **turn** out that those **closures** **remain** **unchanged** in the **final** result ; hence their **creation** is **unnecessary** .

###The Corpus Reference Sentences :
0.555380014938


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.228747242846


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.975885265699


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

In addition , the **search** for already **existing** **instances** of **active** data **structures** in the **copy** **environment** and **merging** of **environments** for **successive** **unifications** causes an **additional** **overhead** .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.634915014534


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

1.0


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

**Similarly** , in **Kogure** 's approach , not all **redundant** **copying** is **avoided** in **cases** where there **exists** a **feature** **path** ( a **sequence** of **nodes** **connected** by **arcs** ) to a **node** that needs to be **copied** .

###The Corpus Reference Sentences :
0.943205752572


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.972806659746


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.084616139424


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

All the **nodes** along such a **path** must be **copied** , even if they are not **affected** by the **unification** **procedure** .

###The Corpus Reference Sentences :
1.0


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

1.0


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.333656499585


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



##The Citing Sentences :

Furthermore , **special** **copy** **dependency** **information** has to be **maintained** while **copying** **nodes** in order to **trigger** **copying** of such **arc** **sequences** **leading** to a **node** where **copying** is **needed** later in the process of **unification** .

###The Corpus Reference Sentences :
0.879298884386


**23** :
**Copying** **sharable** **parts** is **called** **redundant** **copying** .

0.92705721061


**141** :
5 **disables** **structure** **sharing** , **ttowever** , this whole **copying** is not necessary if a **lazy** **evaluation** method is used .

0.106687713909


**142** :
With such a method , it is possible to **delay** **copying** a **node** until either its own **contents** need to change ( e.g. , **node** **G3/Ka** c ! 7 > ) or until it is **found** to have an **arc** ( **sequence** ) to a **node** t , **hat** needs to be **copied** ( e.g. , **node** X **G3/** < a c > in Fig .


###Our Reference Sentences :
0.00437731935807

**118** :
IF Eq ? ( ***node*** ***node*** 2 THEN ***returns*** ( ***node*** 1 .


0.00656466898331

**130** :
**AddArc** ( out ***node*** **complementary** new ***node*** .


0.0080110634425

**120** :
ELSE out ***node*** **GetOutNode** ( ***node*** ***node*** 2 ***meet*** ) .


0.00992663417984

**163** :
IF ***current*** ? ( ***node*** ) THEN ***returns*** ( ***node*** ) .


0.0116169693881

**117** :
***node*** 2 **Dereferencelnode2** ) .



#analysing the annotation 17
**Not valid annotation**
